---
layout: post
img: /images/wordle/funny-money.jpg
title: Writing Wordle bots for fun and profit
excerpt_separator: <!--more-->
---

Shortly after [Wordle](https://www.nytimes.com/games/wordle/index.html) became an overnight
sensation, a natural question arose: what's the best guessing strategy?
Many theories sprung up as people claimed to have found the optimal
way to beat Wordle, often times using the word optimal loosely. While scrolling through
the comments of one of these allegedly optimal Wordle posts I spotted [a comment](https://news.ycombinator.com/item?id=29928263#29928609)
promoting a botting competition to see who could put their money where their mouth was. <!--more-->
Scoring worked as follows:
1. For every submission, 1000 secret words would be chosen randomly with replacement from the set of 12972 valid Wordle words.
2. The bot picks a first guess for each of the 1000 words, and submits them as a batch.
3. The bot is given feedback about each guess in the form of green/yellow/gray positions.
4. This continues until the bot has correctly guessed each of the 1000 secrets.
5. The overall score is the total number of guesses used to determine all 1000 secrets

In this system, the best possible score would be 1000 if your bot somehow managed to
correctly guess each of the 1000 secrets on the first turn. Impossible, right?

## All's fair in love and Wordle

I normally don't join competitions unless I'm pretty sure I can either win, or do
something funny (usually the latter). When I heard about the Wordle bot competition,
I had an idea for how to do both. In a past life I was a [TA for a programming class](/2021/07/02/Teaching/)
where I worked on autograding student submitted code. Running arbitrary
code from potentially adversarial students meant I had a great excuse to practice pentesting
on our grading infrastructure:

![Screenshot of autograder output, scored 1337 points out of 100](/images/wordle/zoinks.jpg)<br>
*Note to students: don't try this sort of thing without permission : )*

My first instinct was to find a way to cheese the competition's scoring system.
The contest came with a [Python SDK](https://github.com/botfights/botfights-sdk/)
for creating and submitting bots, and one ~~cursed~~ neat utility in Python's standard library
lets you inspect the call stack at runtime. For example, if we wanted a function that
conveniently always guessed the correct value of a secret stored two stack frames above
it, we could do something like:

```python
import inspect

def play(_):
    outer_frame = inspect.stack()[2][0]
    return outer_frame.f_locals["secret"]
```

Running this in the SDK's local testing mode yielded a perfect score of 1000! However upon submitting:

```python
Creating fight on botfights.io ...
Fight created: https://botfights.io/fight/fksbk7qu
Traceback (most recent call last):
  File "cheat.py", line 4, in play
    return inspect.stack()[2][0].f_locals["secret"]
KeyError: 'secret'
```

Oof, what happened? I falsely assumed the contest would score submissions
by running the bot code in a server side environment, similar to
[Gradescope](https://www.gradescope.com/) or [Kaggle](https://www.kaggle.com/). In
reality, the bot code was executed entirely client side while the secret words were kept
entirely on the server. At this point I had already sunk ten minutes of my life trying to secure
first place illegitimately, so naturally I decided to spend an entire weekend
getting first place legitimately. Of course with so many people claiming to already have the
optimal strategy, there was no way I could win. Right?

## Heuristics are approximations

Many of the people who claimed to have found the optimal strategy were [maximizing information gain](https://en.wikipedia.org/wiki/Information_gain_(decision_tree))
by guessing words which minimize the expected amount of [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory))
once the guess's feedback is returned. The popular math educator
[3Blue1Brown](https://en.wikipedia.org/wiki/3Blue1Brown) even uploaded an ambitiously titled
video "The mathematically optimal Wordle strategy" using this method:


<a href="https://www.youtube.com/watch?v=v68zYyaEmEA" target="_blank" rel="noopener noreferrer">
<img src="/images/wordle/woops2.jpg" style="max-height:40vh; width:auto;" alt="Thumbnail of a video titled The mathematically optimal Wordle strategy"/>
</a>

This was retitled a few days later to ["Solving Wordle using information theory"](https://www.youtube.com/watch?v=v68zYyaEmEA)
when [bugs in the original implementation](https://www.youtube.com/watch?v=fRed0Xmc2Wg)
were found. This is by no means a knock against 3Blue1Brown, and I highly recommend watching his video.
The rest of this section requires a high-level understanding of the information
theory behind Wordle, and the video does an incredible job of explaining it.

The issue with the entropy heuristic is when a guess "partitions" the
possible values of the secret word based on feedback, the entropy formula assumes smaller partitions
are *always* better than larger ones for getting closer to the answer. In reality, the
asymmetric nature of the English lexicon means some subsets of words are trickier to deal
with even if they have the same or fewer number of elements as another subset. Borrowing from
[Alex Peattie's elegant proof regarding minimizing maximum guesses](https://alexpeattie.com/blog/establishing-minimum-guesses-wordle/),
imagine a scenario where the secret word has been narrowed down to four options:
`BILLS`, `CILLS`, `DILLS` and `GILLS`. An optimal guess here is `DEBUG`:

<img src="/images/wordle/subset-4.jpg"  style="max-height:25vh; width:auto;">

The feedback from guessing `DEBUG` always gives us enough information to distinguish which of the
four is the secret word, allowing us to guess the correct word on the next turn. On average, we can solve this
subset of Wordle in exactly 2 guesses. Now consider the case where the
secret words are `WACKY`, `TRICK`, `LEAKS`, `EXTRA`, and `STATE`:

<img src="/images/wordle/subset-5.jpg"  style="max-height:29.5vh; width:auto;">

We can immediately guess `EXTRA`, which has a 20% chance of being correct, otherwise we
always receive enough information to get the correct answer on the second guess.
On average we can expect to solve the 5-word subset (2.3 bits of entropy)
in 1.8 guesses, an improvement over the 4-word subset (2 bits of entropy) in 2 guesses.
If we know the entropy minimization strategy isn't necessarily optimal, what can we
do to improve it? My strategy was nearly identical to the entropy minimization strategy,
except it incorporated [beam search](https://en.wikipedia.org/wiki/Beam_search):

Rather than greedily choosing the guess which minimizes entropy, we can instead explore the top N guesses
(ranked by entropy) and choose the one which ultimately minimizes the expected number of guesses
by recursively looking ahead in the decision tree.
This explores parts of the search space which superficially appear
worse but may be faster to solve, like in the 4-word vs. 5-word case. In practice,
a beam width of 50 is enough to correctly generate the optimal decision tree in classic Wordle (see [Alex Selby's excellent write-up for details](http://sonorouschocolate.com/notes/index.php?title=The_best_strategies_for_Wordle)), though for the competition I only used 10.

## And the winner is...

<img src="/images/wordle/winner.jpg"  style="max-height:20vh; width:auto;">

After three weeks, the contest ended and [I came out on top](https://web.archive.org/web/20220521050613/https://botfights.ai/tournament/botfights_i)! Nice, Although to be
take with a grain of salt. There were only 20 or so other competitors, many of whom
had converged on the same entropy minimization idea. A few of the other contestants
also discussed beam search but never implemented it, thinking it would be intractable in pure Python.
Their intuition was right, and my Python code was basically just a wrapper around a decision tree
precomputed in Rust with a handful of caching tricks so the strategy would be ready
before the heat death of the universe.

Over the next couple of weeks, [Botfights II](https://web.archive.org/web/20220521065315/https://botfights.ai/tournament/botfights_ii)
and [Botfights III](https://web.archive.org/web/20220521055448/https://botfights.ai/tournament/botfights_iii)
began, which used 6-letter words and arbitrary length words as secrets respectively. In
both cases I won by reusing the same beam search approach to get
reasonably effective decision trees that outperformed the greedy entropy minimization approach.
By then I had won about 60 bucks in Bitcoin as the organizer started the final competition...

Continued in the next post: [Hyper-Wordle strategies](/2025/08/24/Hyper-Wordle/).

<!--
## Wacky trick leaks extra state

As you might guess, the next event was
[Botfights IV](https://web.archive.org/web/20220521064114/https://botfights.ai/tournament/botfights_iv).
Previous iterations of the contest kept things interesting by increasing the number of
potential hidden words. The twist in the final contest was a bit different:
* The contest would returned to the original list of 12972 five-letter words.
* All of the secret words were chosen from the 2315 words in the
  [secret list](https://www.wordunscrambler.net/word-list/wordle-word-list) which
  the original Wordle website used.
* Each submission was tested against all 2315 of the possible secret words (**sampled without
  replacement**). In other words, each submission was tested against a permutation of the
  2315 secret words.
* The 2315 secret words still needed to be solved "in parallel" (submit 2315 first guesses,
  receive 2315 pieces of feedback, submit 2315 second guesses, etc...).


I call this Hyper-Wordle, since it can be viewed as a much larger, much more intractable
version of normal Wordle:
-->
<style>
table{
    border-spacing: 50px;
    border:1px solid #000000;
}

th{
    border: 1px solid #000000;
    padding: 3px;
    max-width: 40vw;
}

td{
    border:1px solid #000000;
    padding: 3px;
    max-width: 40vw;
}
</style>

<!--
| **Wordle**                                                                   | **Hyper-Wordle**                                                                                          |
|------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|
| Secrets are chosen from the $$2315$$ possible 5-letter secret words.     | Secrets are chosen from the $$2315!$$ possible permutations of 5-letter secret words.                 |
| Guesses can be chosen from $$12972$$ possible 5-letter words.            | Guesses can be chosen from $$12972^{2315}$$ possible permutations with repetition of 5-letter words. |
| Feedback is given in the form of 5 colored squares.                      | Feedback is given in the form of $$5 \times 2315 = 11575$$ colored squares.                           |
| Your score is the number of guesses needed to identify the secret.       | Your score is the sum of the number of guesses needed to identify every word in the secret permutation.      |

-->
<!--
# Retrospective: was all of this effort worth it?

Probably not, although a handful of good things came out of it:
* It gave me some funny stories and something worth doing a writeup on.
* I received some prize money for winning each of the competitions, about $80 of BTC in total. In itself this isn't worth a ton to me, but watching it decay in value by 55% in the first few months after receiving it was a neat lesson in cryptocurrency volatility, without having to stake any of my own money.
* Inspired me to write the 16 bottles of wine riddle.

On the downside, I now have an overwhelming amount of incredibly useless knowledge about
optimal Wordle. While I'd heard the phrase "cursed for knowledge" before, I never
truly understood it until Wordle came up while I was getting my teeth cleaned:

**Oral Hygienist**: Have you heard of a game called Wordle? My whole family loves it!<br>
**Me**: Mhmha uhuh<br>
**Oral Hygienist**: My go to starting word is "ocean", but my daughter always starts with "raise"<br>
**Me**: *Mentally gauging how hard it would be to talk about optimal Wordle strategies with a regular person*<br>
**Me**: Hmm mhm<br>

# Conclusion

Aiyah is a five-letter word.

# What is optimal Wordle?

I'm just going to assume you already know what Wordle is. But what is optimal Wordle? It turns out to be a controversial topic:
* Early in the year lots of posts started appearing on [Hacker News](https://news.ycombinator.com) about supposedly [optimal Wordle](https://towardsdatascience.com/optimal-wordle-d8c2f2805704) strategies. Many of these weren't really optimal, they just used reasonably effective heuristics based on letter distributions.
* Lots of debate was sparked over what it actually meant for a strategy to be optimal. Is it cheating to use the [secret list](https://www.wordunscrambler.net/word-list/wordle-word-list) of possible answers? Should we minimize the expected value of guesses needed? Or minimize the maximum number of guesses needed? What about hard mode?
* Lots of debate about if debating about what constitutes optimal Wordle is unproductive and if it ruins the point of Wordle.

One surprising event in all of this was when the popular math educator [3Blue1Brown](https://en.wikipedia.org/wiki/3Blue1Brown) uploaded an ambitiously titled video:

![Thumbnail of a video titled "The mathematically optimal Wordle strategy"](/images/wordle/woops.jpg)

 This was retitled a few days later to [Solving Wordle using information theory](https://www.youtube.com/watch?v=v68zYyaEmEA) when [bugs in the original implementation](https://www.youtube.com/watch?v=fRed0Xmc2Wg) were found, although even without the bugs the solution generated wasn't necessarily optimal. This isn't meant to be a knock at 3B1B, but rather an example of how tricky it is to get the definition right. In particular, the 3B1B video used a *very* effective heuristic to generate the decision tree, but at the end of the day heuristics usually aren't the real optimization criteria.

For real optimality results, Laurent Porrier compiled a [list of all the Wordle optimality results so far](https://www.poirrier.ca/notes/wordle-optimal/) which is still being actively updated as of when this is being written! In this post, optimal refers to any strategy that minimizes the expected number of guesses needed to solve a word uniformly sampled from the secret list, and with no limit on the number of guesses.


Probably not, although a handful of good things came out of it:
* I suspect that using Python has done irreparable damage to my ability to estimate just how fast things *can* be. The act of switching from Python to Rust without doing any application level optimization tricks sped up the time to build decision trees by an order of magnitude. It took me another hour before I recalled the words of my [government assigned Rust evangelist](https://twitter.com/exists_forall?lang=en): "Did you remember to use the `--release` flag?" This gave me another order of magnitude improvement for free, and was a nice wake-up call about just how slow Python is.
* It gave me a funny story and something worth doing a write-up on.
* I received some prize money for winning each of the competitions, about $80 of BTC in total. In itself this isn't worth a ton to me, but watching it decay in value by about 55% over the last few months was a valuable lesson in just how volatile cryptocurrency is, without having to stake any of my own money.

I suspect this might turn the game into an incredibly convoluted version of the [Monte Hall Problem](https://en.wikipedia.org/wiki/Monty_Hall_problem).

* What are the necessary conditions for mixed strategies to outperform a single strategy? One thought experiment is to imagine a version Wordle where every possible 26^5 letter combination is treated as valid word. My intuition here would be that this version would be too "symmetric" to beat

* I suspect that using Python has done irreparable damage to my ability to estimate just how fast things *can* be. The act of switching from Python to Rust without doing any application level optimization tricks sped up the time to build decision trees by an order of magnitude. It took me another hour before I recalled the words of my [government assigned Rust evangelist](https://twitter.com/exists_forall?lang=en): "Did you remember to use the `--release` flag?" This gave me another order of magnitude improvement for free, and was a nice wake-up call about just how slow Python is.
-->
